Lee Stott [Microsoft]
 is now a speaker. — 7/3/25, 1:54 PM
Mojan
 is now a speaker. — 7/3/25, 1:54 PM
Mojan
 is now a speaker. — 7/3/25, 1:54 PM
Lee Stott [Microsoft]
 started Foundry Models AMA:  SLM & Reasoning Models — 7/3/25, 2:00 PM
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳
 is now a speaker. — 7/3/25, 2:00 PM
takescake — 7/3/25, 2:00 PM
1 PM here
ManojMungamuri — 7/3/25, 2:01 PM
India
Korey — 7/3/25, 2:01 PM
🇸🇪
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:01 PM
Hello from New York!! 🗽🇺🇸
Lee Stott [Microsoft] — 7/3/25, 2:01 PM
Welcome to todays session from the UK.
Mapaks — 7/3/25, 2:01 PM
Canada
Vryheid Jobeer — 7/3/25, 2:01 PM
South Africa
Swapnil Dey — 7/3/25, 2:01 PM
Kolkata India
takescake — 7/3/25, 2:02 PM
🙂
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:02 PM
Welcome everyone - I'll try to keep sharing relevant links here in case you missed the Monday livestream
Korey — 7/3/25, 2:02 PM
hey @takescake @perfectstorm
Nisal gunawardhana — 7/3/25, 2:02 PM
Hey 👋  I’m here from Sri Lanka 🇱🇰
Lee Stott [Microsoft] — 7/3/25, 2:02 PM
Welcome everyone!
Shivamm — 7/3/25, 2:02 PM
Hellooo
Lee Stott [Microsoft] — 7/3/25, 2:03 PM
You can see all of @Mojan slides and resources in the ⁠model-mondays  channel
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:03 PM
You can watch the replay of Mojan's talk here: https://aka.ms/model-mondays/playlist
YouTube
Model Mondays
Coming soon! Model Mondays - new episodes Mondays at 10:30 AM PT / 1:30 PM ET
Image
Lee Stott [Microsoft] — 7/3/25, 2:04 PM
And yes the cat is called Shadow 🙂
takescake
 is now a speaker. — 7/3/25, 2:04 PM
Lee Stott [Microsoft] — 7/3/25, 2:06 PM
see https://github.com/microsoft/olive @takescake  its really simple key thing is you will need a GPU with around 16GB of memory
GitHub
GitHub - microsoft/Olive: Olive: Simplify ML Model Finetuning, Conv...
Olive: Simplify ML Model Finetuning, Conversion, Quantization, and Optimization for CPUs, GPUs and NPUs. - microsoft/Olive
GitHub - microsoft/Olive: Olive: Simplify ML Model Finetuning, Conv...
perfectstorm — 7/3/25, 2:06 PM
Hello shadow 🙂

we are using phi-4-reasoning-plus & hosting it locally with ollama.

when i use ai toolkit in vscode, i can add ollama & see the phi-4 model. Unfortunately, i see there is no tool support in phi-4. Is this expected or am i missing something?
Vryheid Jobeer — 7/3/25, 2:06 PM
The smaller LLMs that's available what does the active parameters, context window, token input/output limitations looks like?
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:06 PM
The key slide from Mojan's talk on Monday about the two Phi-4-reasoning models - you can find her deck on the Model-Mondays repo: https://github.com/microsoft/model-mondays
Image
Akash — 7/3/25, 2:07 PM
I have questions where we can re-watch podcasts?
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:08 PM
The links are on the forum chat card here https://github.com/orgs/azure-ai-foundry/discussions/76

Quantized versions
https://huggingface.co/microsoft/Phi-4-reasoning-onnx
https://huggingface.co/microsoft/Phi-4-reasoning-plus-onnx

Tutorials
https://docs.unsloth.ai/basics/tutorials-how-to-fine-tune-and-run-llms/phi-4-reasoning-how-to-run-and-fine-tune
https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/ 
Shivamm — 7/3/25, 2:08 PM
Refer ⁠model-mondays - all are listed there
perfectstorm — 7/3/25, 2:09 PM
understood, thank you
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:10 PM
Model pages on Azure AI Foundry:
https://ai.azure.com/catalog/models/Phi-4-reasoning
AI Model Catalog | Microsoft Foundry Models
Explore the comprehensive catalog of AI models from Microsoft Foundry
Shivamm — 7/3/25, 2:10 PM
Model catalog is also a good resource to refer about those
Vryheid Jobeer — 7/3/25, 2:12 PM
Thank you
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:12 PM
Phi-4-Reasoning is also on GitHub Models for those who want to explore it with just their GitHub account https://github.com/marketplace/models/azureml/Phi-4-reasoning/playground
takescake — 7/3/25, 2:13 PM
How can a LORA help my prompts how do i apply it?
Lee Stott [Microsoft] — 7/3/25, 2:14 PM
You can see some great examples at the Phi Cookbook https://aka.ms/phicookbook
GitHub
GitHub - microsoft/PhiCookBook: This is a Phi Family of SLMs book f...
This is a Phi Family of SLMs book for getting started with Phi Models. Phi a family of open sourced AI models developed by Microsoft. Phi models are the most capable and cost-effective small langua...
This is a Phi Family of SLMs book for getting started with Phi Models. Phi a family of open sourced AI models developed by Microsoft. Phi models are the most capable and cost-effective small langua...
perfectstorm — 7/3/25, 2:15 PM
for models that i use for an agent planner for a 2 or 3 agent scenario, i am assuming i need reasoning & tools. if this is true, any suggestions for which of (the many!) benchmarks to pay attention to?
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:16 PM
The BFCL benchmark https://gorilla.cs.berkeley.edu/leaderboard.html (tool use and agentic evals) 
Berkeley Function Calling Leaderboard V3 (aka Berkeley Too...
Explore The Berkeley Function Calling Leaderboard (also called The Berkeley Tool Calling Leaderboard) to see the LLM's ability to call functions (aka tools) accurately.
perfectstorm — 7/3/25, 2:17 PM
thank you
Shivamm — 7/3/25, 2:17 PM
https://github.com/microsoft/Foundry-Local
GitHub
GitHub - microsoft/Foundry-Local
Contribute to microsoft/Foundry-Local development by creating an account on GitHub.
Contribute to microsoft/Foundry-Local development by creating an account on GitHub.
https://learn.microsoft.com/azure/ai-foundry/foundry-local/get-started?WT.mc_id=%3Fwt.mc_id%3DMVP_452430

⁠foundry-local
Akash — 7/3/25, 2:18 PM
Not yet
Nitya Narasimhan, PhD 🗽🇺🇸🇮🇳 — 7/3/25, 2:18 PM
Also check out the Observability docs on Azure AI Foundry to learn about and use evals for agents and more https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/observability
Vryheid Jobeer — 7/3/25, 2:19 PM
Phi models are there transparency regarding training and I assume it's domain specific? How do I know where and how to abuse it?
perfectstorm — 7/3/25, 2:19 PM
our use case is to translate optimization problems (max-cut, qubo,....) into python that can subsequently be executed. we are experimenting with a variety of models & wer surprised how well phi-4 did. we did not expect the level of code output.
Vryheid Jobeer — 7/3/25, 2:23 PM
Thank you
